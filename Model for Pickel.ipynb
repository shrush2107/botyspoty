{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF=pd.read_csv(\"clean.csv\",encoding='mac_roman', na_filter=True, na_values='[]')\n",
    "trainDF.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>Labels</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Turns out the cop did not even bake that fucki...</td>\n",
       "      <td>1</td>\n",
       "      <td>turns cop even bake fucking cake</td>\n",
       "      <td>['turns', 'cop', 'even', 'bake', 'fucking', 'c...</td>\n",
       "      <td>['turn', 'cop', 'even', 'bake', 'fucking', 'ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@realDonaldTrump Hey Don! You up? Donnnnaaald!...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey donnnnaaald awake</td>\n",
       "      <td>['hey', 'donnnnaaald', 'awake']</td>\n",
       "      <td>['hey', 'donnnnaaald', 'awake']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Man drowned in Nichols home is 5th hurricane d...</td>\n",
       "      <td>1</td>\n",
       "      <td>man drowned nichols home th hurricane death sc...</td>\n",
       "      <td>['man', 'drowned', 'nichols', 'home', 'th', 'h...</td>\n",
       "      <td>['man', 'drowned', 'nichols', 'home', 'th', 'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It‚Äö√Ñ√¥s time to phase immigration down so w...</td>\n",
       "      <td>1</td>\n",
       "      <td>time phase immigration phase americans back</td>\n",
       "      <td>['time', 'phase', 'immigration', 'phase', 'ame...</td>\n",
       "      <td>['time', 'phase', 'immigration', 'phase', 'ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calm is a superpower.  ‚Äö√∫√•  https://t.co/B...</td>\n",
       "      <td>1</td>\n",
       "      <td>calm superpower</td>\n",
       "      <td>['calm', 'superpower']</td>\n",
       "      <td>['calm', 'superpower']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  Labels  \\\n",
       "0           0  Turns out the cop did not even bake that fucki...       1   \n",
       "1           1  @realDonaldTrump Hey Don! You up? Donnnnaaald!...       0   \n",
       "2           2  Man drowned in Nichols home is 5th hurricane d...       1   \n",
       "3           3  It‚Äö√Ñ√¥s time to phase immigration down so w...       1   \n",
       "4           4  Calm is a superpower.  ‚Äö√∫√•  https://t.co/B...       1   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                   turns cop even bake fucking cake   \n",
       "1                              hey donnnnaaald awake   \n",
       "2  man drowned nichols home th hurricane death sc...   \n",
       "3        time phase immigration phase americans back   \n",
       "4                                    calm superpower   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  ['turns', 'cop', 'even', 'bake', 'fucking', 'c...   \n",
       "1                    ['hey', 'donnnnaaald', 'awake']   \n",
       "2  ['man', 'drowned', 'nichols', 'home', 'th', 'h...   \n",
       "3  ['time', 'phase', 'immigration', 'phase', 'ame...   \n",
       "4                             ['calm', 'superpower']   \n",
       "\n",
       "                                   text_tokens_lemma  \n",
       "0  ['turn', 'cop', 'even', 'bake', 'fucking', 'ca...  \n",
       "1                    ['hey', 'donnnnaaald', 'awake']  \n",
       "2  ['man', 'drowned', 'nichols', 'home', 'th', 'h...  \n",
       "3  ['time', 'phase', 'immigration', 'phase', 'ame...  \n",
       "4                             ['calm', 'superpower']  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=trainDF['text_tokens_lemma']\n",
    "Y=trainDF['Labels']\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text_tokens_lemma'])\n",
    "pickle.dump(count_vect, open('cv.pkl','wb'))\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<66128x44572 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 525597 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  806   643]\n",
      " [  208 14876]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9485271880481462"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loreg=linear_model.LogisticRegression(max_iter=200)# initialize the model\n",
    "loreg.fit(xtrain_count, train_y) # fit he model\n",
    "pickle.dump(loreg, open('model.pkl','wb'))\n",
    "y_pred=loreg.predict(xvalid_count) # now predict\n",
    "cm = confusion_matrix(valid_y, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(valid_y, y_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case it\n",
    "#take input\n",
    "#remove everything apart from a-zA-Z\n",
    "#remove numbers\n",
    "#tokenize it\n",
    "#remove stopwords\n",
    "#lemmetize it\n",
    "#pass lemmetized sentence through count vectors\n",
    "#pass through model\n",
    "#get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open('cv.pkl','rb'))\n",
    "model = pickle.load(open('model.pkl','rb'))\n",
    "review=input(\"Enter a tweet:\")\n",
    "wordnet = WordNetLemmatizer()\n",
    "corpus = []\n",
    "review = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", '', review)\n",
    "review = re.sub(r\"\\d+\", '', review)\n",
    "review = review.lower()\n",
    "review= nltk.word_tokenize(review)\n",
    "review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "review = ' '.join(review)\n",
    "corpus.append(review)\n",
    "print(corpus)\n",
    "corpus = cv.transform(corpus)\n",
    "print(model.predict(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot Tweeted\n"
     ]
    }
   ],
   "source": [
    "if(model==0):\n",
    "    print(\"Human Tweeted\")\n",
    "else:\n",
    "    print(\"Bot Tweeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
